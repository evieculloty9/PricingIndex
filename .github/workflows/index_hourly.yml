name: Forward Compute Index — Hourly Build & Deploy

on:
  workflow_dispatch:
  schedule:
    - cron: "5 * * * *" # every hour at minute 5

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "forward-compute-index"
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.12"
  COMMIT_DATA: "true"
  HISTORY_RETENTION_HOURS: "0" # keep ALL history

jobs:
  build-and-bundle:
    runs-on: ubuntu-latest
    timeout-minutes: 40

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          set -e
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install chromium || true
          playwright install-deps || true

      - name: Run hourly scrape + index (master runner)
        env:
          HCPI_DATABASE_URL: ${{ secrets.HCPI_DATABASE_URL }}
          LAMBDA_API_KEY: ${{ secrets.LAMBDA_API_KEY }}
          RUNPOD_API_KEY: ${{ secrets.RUNPOD_API_KEY }}
          HISTORY_RETENTION_HOURS: ${{ env.HISTORY_RETENTION_HOURS }}
        run: |
          set -e
          echo "Running master_runner.py for ALL providers…"
          python master_runner.py --cron --db "${HCPI_DATABASE_URL:-sqlite:///hcpi.db}"
          echo "Pipeline execution complete."

      - name: One-off backfill (manual only)
        if: github.event_name == 'workflow_dispatch'
        run: |
          set -e
          echo "Backfill requested (manual dispatch)."
          if [ ! -f scripts/backfill_legacy_to_hcpi.py ]; then
            echo "ERROR: scripts/backfill_legacy_to_hcpi.py not found"; exit 1
          fi
          if ! ls data/history/*_history.csv >/dev/null 2>&1; then
            echo "ERROR: No legacy CSVs in data/history/*_history.csv"; exit 1
          fi
          python scripts/backfill_legacy_to_hcpi.py --src data/history --out hcpi/hcpi_history.json
          echo "After backfill, point count:"
          pts=$(grep -o '"timestamp"' hcpi/hcpi_history.json | wc -l | tr -d ' ')
          echo "points=$pts"
          if [ "$pts" -lt 700 ]; then
            echo "ERROR: Backfill did not add enough history (points=$pts, need >=700)."; exit 1
          fi

      - name: Verify generated data & history
        run: |
          set -e
          echo "==== Latest CSV ===="
          test -f data/derived/provider_scores_latest.csv || (echo "ERROR: provider_scores_latest.csv missing"; exit 1)
          wc -l data/derived/provider_scores_latest.csv || true
          head -3 data/derived/provider_scores_latest.csv || true
          tail -3 data/derived/provider_scores_latest.csv || true

          echo ""
          echo "==== Provider History CSV ===="
          if [ -f data/history/provider_scores_history.csv ]; then
            wc -l data/history/provider_scores_history.csv || true
            tail -5 data/history/provider_scores_history.csv || true
          else
            echo "WARNING: provider_scores_history.csv not found (will be created on next runs)"
          fi

          echo ""
          echo "==== Index History CSV ===="
          if [ -f data/history/index_history.csv ]; then
            wc -l data/history/index_history.csv || true
            tail -5 data/history/index_history.csv || true
          else
            echo "WARNING: index_history.csv not found (will be created on next runs)"
          fi

          echo ""
          echo "==== HCPI History JSON ===="
          if [ -f hcpi/hcpi_history.json ]; then
            echo -n "Points: "; grep -o '"timestamp"' hcpi/hcpi_history.json | wc -l || true
            echo "Size:   $(du -h hcpi/hcpi_history.json | cut -f1)"
            echo "First timestamp:"
            python - <<'PY'
import json
with open("hcpi/hcpi_history.json") as f:
    j = json.load(f)
print((j[0] or {}).get("timestamp") if j else "EMPTY")
PY
            echo "Last timestamp:"
            python - <<'PY'
import json
with open("hcpi/hcpi_history.json") as f:
    j = json.load(f)
print((j[-1] or {}).get("timestamp") if j else "EMPTY")
PY
          else
            echo "WARNING: hcpi/hcpi_history.json not found"
          fi

      - name: Commit generated data to repository
        if: env.COMMIT_DATA == 'true'
        uses: EndBug/add-and-commit@v9
        with:
          add: |
            data/derived/*.csv
            data/history/*.csv
            hcpi/*.json
            hcpi/*history*.csv
          message: "ci: hourly data update [skip ci]"
          author_name: github-actions
          author_email: actions@github.com

      - name: Prepare static site (public/)
        run: |
          set -e
          mkdir -p public/data/derived public/data/history public/hcpi

          echo "==== Copying HTML ===="
          if [ -f docs/index.html ]; then
            cp -v docs/index.html public/index.html
          elif [ -f index.html ]; then
            cp -v index.html public/index.html
          else
            echo '<!doctype html><meta charset="utf-8"><title>Forward Compute Index</title><body style="font:14px system-ui;padding:24px;color:#e7edf3;background:#0f1216"><h1>Forward Compute Index</h1><p>No dashboard found. Add <code>docs/index.html</code> to the repo.</p></body>' > public/index.html
          fi

          echo "==== Copying data files ===="
          cp -v data/derived/*.csv public/data/derived/ 2>/dev/null || true
          cp -v data/history/*.csv  public/data/history/  2>/dev/null || true
          cp -v hcpi/*.json         public/hcpi/          2>/dev/null || true
          cp -v hcpi/*history*.csv  public/hcpi/          2>/dev/null || true

          echo "==== Verify copied files ===="
          wc -l public/data/derived/provider_scores_latest.csv || true
          wc -l public/data/history/provider_scores_history.csv 2>/dev/null || echo "No provider history CSV yet"
          wc -l public/data/history/index_history.csv 2>/dev/null || echo "No index history CSV yet"
          ls -lh public/hcpi/hcpi_history.json 2>/dev/null || echo "No HCPI history JSON yet"

          echo "==== public/ tree ===="
          find public -type f -print

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build-and-bundle
    runs-on: ubuntu-latest
    timeout-minutes: 10
    environment:
      name: github-pages
    permissions:
      pages: write
      id-token: write
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4



